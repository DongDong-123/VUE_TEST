webpackJsonp([28],{JfYe:function(t,i){},Rfsj:function(t,i){t.exports="data:image/png;base64,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"},lb4r:function(t,i,e){"use strict";Object.defineProperty(i,"__esModule",{value:!0});var s={render:function(){this.$createElement;this._self._c;return this._m(0)},staticRenderFns:[function(){var t=this,i=t.$createElement,e=t._self._c||i;return e("div",{staticClass:"arithmetic-dialog"},[e("div",{staticClass:"title1"},[t._v("逻辑回归-二分类")]),t._v(" "),e("div",{staticClass:"title2"},[t._v("1.算法简述")]),t._v(" "),e("div",{staticClass:"dialog-desc textIndent"},[t._v("\n    LR（Logistic Regression）逻辑回归是业界常用的监督学习算法，常见用于对类别的预测，可以完成高维度，大样本数据下的快速建模场景。\n    适用场景\n    特征场景：\n    尽量将连续特征离散化（discrete）之后再使用该算法；\n    若一定要使用连续型特征，可将连续特征作归一化，也就是减去平均值并除以标准差，否则会造成收敛速度不够。\n    业务场景：\n    逻辑回归二分类适用于数值的大小对业务目标影响不大，或者数值范围比较小的场景。如预估，信贷。\n  ")]),t._v(" "),e("div",{staticClass:"title2"},[t._v("2.适用场景")]),t._v(" "),e("div",{staticClass:"dialog-desc"},[t._v("\n    特征场景：\n    "),e("div",{staticClass:"textIndent"},[t._v("尽量将连续特征离散化（discrete）之后再使用该算法；")]),t._v(" "),e("div",{staticClass:"textIndent"},[t._v("若一定要使用连续型特征，可将连续特征作归一化，也就是减去平均值并除以标准差，否则会造成收敛速度不够。")]),t._v(" "),e("div",[t._v("业务场景：")]),t._v(" "),e("div",{staticClass:"textIndent"},[t._v("逻辑回归二分类适用于数值的大小对业务目标影响不大，或者数值范围比较小的场景。如预估，信贷。")])]),t._v(" "),e("div",{staticClass:"title2"},[t._v("3.参数")]),t._v(" "),e("div",{staticClass:"dialog-desc textIndent"},[e("div",[t._v("算法模式：速度优先、效果优先。")]),t._v(" "),e("div",[t._v("最大训练轮数：指对数据训练的最大次数，理论上值越大对训练数据的拟合会越好，同时也会耗费更多的计算资源或时间；该值不能设置太小，对训练数据的拟合会更差，可能会导致欠拟合。取值范围是1~100的整数，可根据自己的数据设定不同的训练轮数。")]),t._v(" "),e("div",[t._v("学习率alpha系数：学习率则是指每次训练的步长尺度，这是影响训练效果最重要的参数；学习率越大一次训练就会越快完成。 取值范围是0~100的实数，建议取值在0~1之间，可以通过多次尝试选择较好的参数设定。")]),t._v(" "),e("div",[t._v("L1正则项系数：损失函数中的L1正则化项系数，该系数越大，学习得到的模型将会越稀疏（即更多的权重为0），但是对训练数据的拟合会更差；该系数越小，对训练数据的拟合会更好，但是同时模型中非0元将会增加（增加最终实时到业务系统中的模型尺寸，影响实时的资源消耗），验证范围是[0,1000000]的实数。")]),t._v(" "),e("div",[t._v("L2正则项系数：损失函数中的L2正则项系数，该系数越大，模型越不容易过拟合到现有数据集，但是会越容易欠拟合；该系数越小，模型对训练数据的拟合会更好，但是更容易过拟合。验证范围是[0,1000000]的实数。")])])])}]},a={render:function(){this.$createElement;this._self._c;return this._m(0)},staticRenderFns:[function(){var t=this,i=t.$createElement,e=t._self._c||i;return e("div",{staticClass:"arithmetic-dialog"},[e("div",{staticClass:"title1"},[t._v("随机森林-二分类")]),t._v(" "),e("div",{staticClass:"title2"},[t._v("1.算法简述")]),t._v(" "),e("div",{staticClass:"dialog-desc textIndent"},[e("div",[t._v("随机森林 (Random Forest) 是一种基于bagging思想的决策树算法。随机森林模型由多棵决策树组成，通过将多棵决策树预测结果进行投票，相比单个决策树有效降低了模型的方差（variance），适用于类别预测问题。")]),t._v(" "),e("div",[t._v("和模型结构类似的GBDT (Gradient Boosted Decision Tree) 相比，随机森林算法的树与树之间可以并行训练，具有训练速度上的优势。")]),t._v(" "),e("div",[t._v("从模型表达能力上，随机森林基于bagging，多棵决策树主要作用是降低模型的方差（variance），提高模型泛化能力，但对降低模型预测偏差（bias）作用有限。")])]),t._v(" "),e("div",{staticClass:"title2"},[t._v("2.适用场景")]),t._v(" "),e("div",{staticClass:"dialog-desc textIndent"},[e("div",{staticClass:"textNormal"},[t._v("特征场景：")]),t._v(" "),e("div",[t._v("基于决策树的算法更适合解决连续特征值的问题，当前的随机森林实现了对离散特征值的分桶策略，因此也可以用于含离散特征数据的训练，但是对于大规模离散特征无法进行有效建模。")]),t._v(" "),e("div",[t._v("例如对于离散特征“性别”，只有两维特征维度，则可以用随机森林建模；对于离散特征“用户ID”，则可能是存在千万不同的用户的大规模离散特征，不适用于随机森林。")]),t._v(" "),e("div",[t._v("因此随机森林更适用于特征维度或样本较少的场景，如果训练结果精度不够，推荐使用GBDT或其他更复杂的模型建模。")]),t._v(" "),e("div",[t._v("使用场景如流失分析、风险评估。")]),t._v(" "),e("div",[t._v("数据集类型：全为连续特征的数据集；包含大量连续特征和少量离散特征的数据集。")]),t._v(" "),e("div",[t._v("数据集规模：无限制 参数规模：较小规模。")])]),t._v(" "),e("div",{staticClass:"title2"},[t._v("3.参数")]),t._v(" "),e("div",{staticClass:"dialog-desc textIndent"},[e("div",[t._v("单棵树的最大深度：森林中单颗决策树的最大深度，控制基模型的模型复杂度。树深度越大，模型复杂度越高，但同时训练时间增长，过拟合的风险也会增加。根据数据量和特征维数调整，通常可设置在5-20之间。默认值为20，取值范围是1~1024的整数。")]),t._v(" "),e("div",[t._v("树的棵树：森林中树的颗数，树的颗数越多，模型方差越小，稳定性越好；增大这个参数能够提升模型泛化性能，但同时训练时间也会增长。默认值为50，取值范围是1~1024的整数 。")]),t._v(" "),e("div",[t._v("连续特征分桶数：数值型连续特征在建模时使用的直方图桶个数，决策树在构造特征分割点时会先将连续特征划分到桶区间，使用区间分割点作为特征分割点的候选，以此降低计算复杂度。桶数目越多，寻找特征分割点就越细致，模型拟合能力就越强，但训练时间也会增长。默认值为20，取值范围是1~8192的整数。")]),t._v(" "),e("div",[t._v("离散特征分桶数：同上，离散特征在建模时也会先映射到桶，以此降低寻找分割点的计算复杂度。默认值为1024，取值范围是1~8192的整数。")])])])}]},v={render:function(){this.$createElement;this._self._c;return this._m(0)},staticRenderFns:[function(){var t=this,i=t.$createElement,e=t._self._c||i;return e("div",{staticClass:"arithmetic-dialog"},[e("div",{staticClass:"title1"},[t._v("朴素贝叶斯-二分类")]),t._v(" "),e("div",{staticClass:"title2"},[t._v("1.算法简述")]),t._v(" "),e("div",{staticClass:"dialog-desc textIndent"},[e("div",[t._v("NB是Naive Bayes的缩写，即朴素贝叶斯，它是基于贝叶斯定理与特征条件独立假设的分类方法。处理思想为：对于给出的待分类项，求解在此项出现的条件下各个类别出现的概率，哪个最大，就认为此待分类项属于哪个类别。")])]),t._v(" "),e("div",{staticClass:"title2"},[t._v("2.适用场景")]),t._v(" "),e("div",{staticClass:"dialog-desc"},[t._v("\n    特征场景：\n    "),e("div",{staticClass:"textIndent"},[t._v("客户是否流失、是否值得投资、欺诈检测。")])])])}]},n={render:function(){this.$createElement;this._self._c;return this._m(0)},staticRenderFns:[function(){var t=this,i=t.$createElement,e=t._self._c||i;return e("div",{staticClass:"arithmetic-dialog"},[e("div",{staticClass:"title1"},[t._v("梯度提升决策树(GBDT)")]),t._v(" "),e("div",{staticClass:"title2"},[t._v("1.算法简述")]),t._v(" "),e("div",{staticClass:"dialog-desc textIndent"},[e("div",[t._v("GBDT(Gradient Boosted Decision Tree) 是一种基于迭代的决策树算法，生成的模型由多棵决策树组成，并将所有树的结论累加作为最终结果，适用于类别预测问题。")])]),t._v(" "),e("div",{staticClass:"title2"},[t._v("2.适用场景")]),t._v(" "),e("div",{staticClass:"dialog-desc"},[t._v("\n    特征场景：\n    "),e("div",{staticClass:"textIndent"},[t._v("GBDT算法善于解决连续值特征的问题，这种问题的特征数一般不多，当特征数在500以下时，使用GBDT的效率较高，但当数据中有离散特征时，使GBDT的效率就会非常低，所以一般来说使用的时候需要保证离散值被过滤掉。")])]),t._v(" "),e("div",{staticClass:"title2"},[t._v("3.参数")]),t._v(" "),e("div",{staticClass:"dialog-desc textIndent"},[e("div",[t._v("学习率：取值范围0~1，建议取值0.01~0.3。 学习率应和树棵数配合调整，两者呈近似反比关系，树棵数越多，学习率应该越小，由此可获得更好的模型效果，并防止过拟合。")]),t._v(" "),e("div",[t._v("单棵树的最大深度：取值范围1~256的整数，建议取值1~10。 该参数是最重要的参数之一，对效果影响很大。理论上，树越深，对数据集的拟合效果越强，需要使用更大量的数据进行训练，但计算所耗内存会呈指数增加，也容易出现过拟合。")]),t._v(" "),e("div",[t._v("树的棵数：取值范围是1~100万，建议取值16~4096。 表示训练的树的数量。理论上，树的棵数越大，对数据集的拟合效果越强，效果越好，但计算所耗资源也会越多，训练时间增长，也容易出现过拟合。")]),t._v(" "),e("div",[t._v("L0正则项系数：损失函数中的正则项系数，L0通过控制总节点数来限制模型的复杂程度，L0越大，叶子数越少，可以防止过拟合。验证范围是[0,1000000]的实数。")]),t._v(" "),e("div",[t._v("L2正则项系数：损失函数中的正则项系数，L2通过控制叶节点权重的平方和来限制模型的复杂程度，L2越大，权重绝对值越小，降低对训练数据集的拟合度，防止过拟合。验证范围是[0,1000000]的实数。")]),t._v(" "),e("div",[t._v("叶子节点最小权重：若当前叶子节点所含样本的权重之和小于叶子节点最小权重时，则不再进行分裂。值越大，树越不容易分裂生长，可以防止过拟合。验证范围是[0,1000000]的实数，与实际样本数有关。")]),t._v(" "),e("div",[t._v("叶子节点最小划分增益：当前叶子节点划分时所需要损失函数的最小下降值，若当前节点分裂产生的损失函数下降值低于该增益值，则不再进行分裂。值越大，树越不容易分裂生长，可以防止过拟合。验证范围是[0,1000000]的实数。")])])])}]},l={render:function(){this.$createElement;this._self._c;return this._m(0)},staticRenderFns:[function(){var t=this,i=t.$createElement,e=t._self._c||i;return e("div",{staticClass:"arithmetic-dialog"},[e("div",{staticClass:"title1"},[t._v("支持向量机(SVM)")]),t._v(" "),e("div",{staticClass:"title2"},[t._v("1.算法简述")]),t._v(" "),e("div",{staticClass:"dialog-desc textIndent"},[e("div",[t._v("支持向量机（简称SVM）是一种经典的分类模型，分类学习最基本的思想就是基于某个训练集，在样本空间中找到一个划分超平面，将不同类别的样本分开。")])]),t._v(" "),e("div",{staticClass:"title2"},[t._v("2.参数")]),t._v(" "),e("div",{staticClass:"dialog-desc textIndent"},[e("div",[t._v("最大训练轮数：最大训练轮数（最大迭代整个训练数据集的次数，大于1的正整数）：该值越大对训练数据的拟合会越好，但是同时可能会导致过拟合；该值越小对训练数据的拟合会更差，但是同时可能会导致欠拟合。取值范围是1~100的整数，实际使用应当根据自己的数据设定不同的训练轮数。")]),t._v(" "),e("div",[t._v("学习率alpha系数：学习率越小就需要越多的树，运行时间就越长，但是一定程度可以防止过拟合并获得更好的效果，在实际使用的时候可根据实际情况对参数做调整。学习率取值范围0~1，建议取值范围是在0.01~0.3之间。")]),t._v(" "),e("div",[t._v("L1正则项系数：损失函数中的L1正则化项系数，该系数越大，学习得到的模型将会越稀疏（即更多的权重为0），但是对训练数据的拟合会更差；该系数越小，对训练数据的拟合会更好，但是同时模型中非0元将会增加（增加最终实时到业务系统中的模型尺寸，影响实时的资源消耗），验证范围是[0,1000000]的实数。")]),t._v(" "),e("div",[t._v("L2正则项系数：损失函数中的L2正则项系数，该系数越大，模型越不容易过拟合到现有数据集，但是会越容易欠拟合；该系数越小，模型对训练数据的拟合会更好，但是更容易过拟合。验证范围是[0,1000000]的实数。")])])])}]},d={render:function(){this.$createElement;this._self._c;return this._m(0)},staticRenderFns:[function(){var t=this,i=t.$createElement,e=t._self._c||i;return e("div",{staticClass:"arithmetic-dialog"},[e("div",{staticClass:"title1"},[t._v("逻辑回归-多分类")]),t._v(" "),e("div",{staticClass:"title2"},[t._v("1.算法简述")]),t._v(" "),e("div",{staticClass:"dialog-desc textIndent"},[e("div",[t._v("逻辑回归-多分类，是LR（Logistic regression）在多分类的推广，与LR一样，同属于广义线性模型。")])]),t._v(" "),e("div",{staticClass:"title2"},[t._v("2.参数")]),t._v(" "),e("div",{staticClass:"dialog-desc textIndent"},[e("div",[t._v("N分类问题：用户需要指定要进行训练的数据的分类数。用户需要十分清楚自己的多分类场景，预定义是多少类的多分类问题。定义的N必须等于或者大于标签种类数。 若所填数值小于上游特征抽取统计的该训练集的分类数，逻辑回归-多分类算子会跑失败。")]),t._v(" "),e("div",[t._v("算法模式：速度优先、效果优先。")]),t._v(" "),e("div",[t._v("最大训练轮数：指对数据训练的最大次数，理论上值越大对训练数据的拟合会越好，同时也会耗费更多的计算资源或时间；该值不能设置太小，对训练数据的拟合会更差，可能会导致欠拟合。取值范围是1~100的整数，可根据自己的数据设定不同的训练轮数。")]),t._v(" "),e("div",[t._v("学习率alpha系数：学习率则是指每次训练的步长尺度，这是影响训练效果最重要的参数；学习率越大一次训练就会越快完成。 取值范围是0~100的实数，建议取值在0~1之间，您可以通过多次尝试选择较好的参数设定。")]),t._v(" "),e("div",[t._v("L1正则项系数：损失函数中的L1正则化项系数，该系数越大，学习得到的模型将会越稀疏（即更多的权重为0），但是对训练数据的拟合会更差；该系数越小，对训练数据的拟合会更好，但是同时模型中非0元将会增加（增加最终实时到业务系统中的模型尺寸，影响实时的资源消耗），验证范围是[0,1000000]的实数。")]),t._v(" "),e("div",[t._v("L2正则项系数：损失函数中的L2正则项系数，该系数越大，模型越不容易过拟合到现有数据集，但是会越容易欠拟合；该系数越小，模型对训练数据的拟合会更好，但是更容易过拟合。验证范围是[0,1000000]的实数。")])])])}]},c={render:function(){this.$createElement;this._self._c;return this._m(0)},staticRenderFns:[function(){var t=this,i=t.$createElement,e=t._self._c||i;return e("div",{staticClass:"arithmetic-dialog"},[e("div",{staticClass:"title1"},[t._v("线性回归")]),t._v(" "),e("div",{staticClass:"title2"},[t._v("1.算法简述")]),t._v(" "),e("div",{staticClass:"dialog-desc textIndent"},[e("div",[t._v("线性回归（Linear regression）是回归分析中第一种经过严格研究并在实际应用中广泛使用的模型。它产生的估计的统计特性也更容易确定。线性回归分析是对客观事物数量关系的分析，是一种重要的统计分析方法，被广泛的应用于社会经济现象变量之间的影响因素和关联的研究。该算法可以完成高维离散，大样本数据下的快速建模。")])]),t._v(" "),e("div",{staticClass:"title2"},[t._v("2.参数")]),t._v(" "),e("div",{staticClass:"dialog-desc textIndent"},[e("div",[t._v("算法模式：速度优先、效果优先。")]),t._v(" "),e("div",[t._v("最大训练轮数：指对数据训练的最大次数，理论上值越大对训练数据的拟合会越好，同时也会耗费更多的计算资源或时间；该值不能设置太小，对训练数据的拟合会更差，可能会导致欠拟合。取值范围是1~100的整数，可根据自己的数据设定不同的训练轮数。")]),t._v(" "),e("div",[t._v("学习率alpha系数：学习率则是指每次训练的步长尺度，这是影响训练效果最重要的参数；学习率越大一次训练就会越快完成。 取值范围是0~100的实数，建议取值在0~1之间，您可以通过多次尝试选择较好的参数设定。")]),t._v(" "),e("div",[t._v("L1正则项系数：损失函数中的L1正则化项系数，该系数越大，学习得到的模型将会越稀疏（即更多的权重为0），但是对训练数据的拟合会更差；该系数越小，对训练数据的拟合会更好，但是同时模型中非0元将会增加（增加最终实时到业务系统中的模型尺寸，影响实时的资源消耗），验证范围是[0,1000000]的实数。")]),t._v(" "),e("div",[t._v("L2正则项系数：损失函数中的L2正则项系数，该系数越大，模型越不容易过拟合到现有数据集，但是会越容易欠拟合；该系数越小，模型对训练数据的拟合会更好，但是更容易过拟合。验证范围是[0,1000000]的实数。")])])])}]},_={render:function(){this.$createElement;this._self._c;return this._m(0)},staticRenderFns:[function(){var t=this,i=t.$createElement,e=t._self._c||i;return e("div",{staticClass:"arithmetic-dialog"},[e("div",{staticClass:"title1"},[t._v("梯度提升回归树(GBRT)")]),t._v(" "),e("div",{staticClass:"title2"},[t._v("1.算法简述")]),t._v(" "),e("div",{staticClass:"dialog-desc textIndent"},[e("div",[t._v("GBRT(Gradient Boosted Regression Tree)，即梯度提升回归树，是一种基于迭代的回归树算法，其核心就在于，每一棵树是从之前所有树的残差中来学习的，适用于回归预测问题。GBRT的优点包括，可处理混合类型的数据和异构特征，对空间外的异常点处理能力强，能自动发掘非线性特征之间的相互作用，预测能力强，可解释性强等。")])]),t._v(" "),e("div",{staticClass:"title2"},[t._v("2.应用场景")]),t._v(" "),e("div",{staticClass:"dialog-desc textIndent"},[t._v("GBRT算法善于解决连续值特征的问题，这种问题的特征数一般不多，当特征数在500以下时，使用GBRT的效率较高，但当数据中有离散特征时，使GBRT的效率就会非常低，所以一般来说使用的时候需要保证离散值被过滤掉。")]),t._v(" "),e("div",{staticClass:"title2"},[t._v("3.参数")]),t._v(" "),e("div",{staticClass:"dialog-desc textIndent"},[e("div",[t._v("学习率：")]),t._v(" "),e("div",[t._v("取值范围0~1，建议取值0.01~0.3。 学习率应和树棵数配合调整，两者呈近似反比关系，树棵数越多，学习率应该越小，由此可获得更好的模型效果，并防止过拟合。")]),t._v(" "),e("div",[t._v("单棵树的最大深度：")]),t._v(" "),e("div",[t._v("取值范围1~256的整数，建议取值1~10。 该参数是最重要的参数之一，对效果影响很大。理论上，树越深，对数据集的拟合效果越强，需要使用更大量的数据进行训练，但计算所耗内存会呈指数增加，也容易出现过拟合。")]),t._v(" "),e("div",[t._v("树的棵数：")]),t._v(" "),e("div",[t._v("取值范围是1~100万，建议取值16~4096。 表示训练的树的数量。理论上，树的棵数越大，对数据集的拟合效果越强，效果越好，但计算所耗资源也会越多，训练时间增长，也容易出现过拟合。")]),t._v(" "),e("div",[t._v("L0正则项系数：")]),t._v(" "),e("div",[t._v("损失函数中的正则项系数，L0通过控制总节点数来限制模型的复杂程度，L0越大，叶子数越少，可以防止过拟合。验证范围是[0,1000000]的实数。")]),t._v(" "),e("div",[t._v("L2正则项系数：")]),t._v(" "),e("div",[t._v("损失函数中的正则项系数，L2通过控制叶节点权重的平方和来限制模型的复杂程度，L2越大，权重绝对值越小，降低对训练数据集的拟合度，防止过拟合。验证范围是[0,1000000]的实数。")]),t._v(" "),e("div",[t._v("叶子节点最小权重：")]),t._v(" "),e("div",[t._v("若当前叶子节点所含样本的权重之和小于叶子节点最小权重时，则不再进行分裂。值越大，树越不容易分裂生长，可以防止过拟合。验证范围是[0,1000000]的实数，与实际样本数有关。")]),t._v(" "),e("div",[t._v("叶子节点最小划分增益：")]),t._v(" "),e("div",[t._v("当前叶子节点划分时所需要损失函数的最小下降值，若当前节点分裂产生的损失函数下降值低于该增益值，则不再进行分裂。值越大，树越不容易分裂生长，可以防止过拟合。验证范围是[0,1000000]的实数。")])])])}]},r={render:function(){this.$createElement;this._self._c;return this._m(0)},staticRenderFns:[function(){var t=this,i=t.$createElement,e=t._self._c||i;return e("div",{staticClass:"arithmetic-dialog"},[e("div",{staticClass:"title1"},[t._v("K-Means")]),t._v(" "),e("div",{staticClass:"title2"},[t._v("1.算法简述")]),t._v(" "),e("div",{staticClass:"dialog-desc textIndent"},[e("div",[t._v("K-Means是一种聚类分析算法，聚类是指试图将数据集中的样本划分为若干个通常是不相干的子集，每个子集称为一个“簇”，通过这样的划分，每个簇可能对应于一些潜在的类别，当然，这些类别概念对聚类算法而言事先是未知的，是在聚类过程中自动形成的簇。")])]),t._v(" "),e("div",{staticClass:"title2"},[t._v("2.参数")]),t._v(" "),e("div",{staticClass:"dialog-desc textIndent"},[e("div",[t._v("聚类中心数K：通过指定聚类的中心数K可以将输入数据表聚类为K个簇（类）。K可取值范围为正整数，示例：10表示将输入样本表分为10类。")]),t._v(" "),e("div",[t._v("最大迭代次数：迭代即为多次进行，通过多次迭代才最有可能找出最符合期望的聚类结果，要注意的是数据越多，迭代次数越多会耗费系统更多的资源，因此需要适量调整以保证任务能正常执行。最大迭代次数取值范围为正整数，示例：25表示最多迭代25次。")]),t._v(" "),e("div",[t._v("初始化模式：聚类分析的先决条件有两个，一个是指定聚类的个数（即K），另一个则是指定中心种子，即以哪K个点为中心来进行聚类，初始化模式参数就是定义我们指定中心种子的方式。2种分别为KMeans++，random。")]),t._v(" "),e("div",[t._v("1. KMeans++：初始随机给定K个簇中心，按照距离最近原则把待分类的样本点分到各个簇，然后按平均法重新计算各个簇的质心，从而确定新的簇心，迭代计算，直到簇心的移动距离小于某个给定的误差值。")]),t._v(" "),e("div",[t._v("2. random：随机选取质心。")]),t._v(" "),e("div",[t._v("初始化步数：如果选择了KMeans算法后，则需要指定迭代的次数，即初始化步数。取值在正整数范围内即可。")]),t._v(" "),e("div",[t._v("收敛阈值：根据上面介绍的聚类分析基本原理，如果新质心和初始质心之间的距离小于某一个设置的收敛阈值可以认为我们进行的聚类已经达到期望的结果，算法终止。取值范围是正实数。")])])])}]},o={components:{arithmeticDialog1:e("C7Lr")(null,s,!1,null,null,null).exports,arithmeticDialog2:e("C7Lr")(null,a,!1,null,null,null).exports,arithmeticDialog3:e("C7Lr")(null,v,!1,null,null,null).exports,arithmeticDialog4:e("C7Lr")(null,n,!1,null,null,null).exports,arithmeticDialog5:e("C7Lr")(null,l,!1,null,null,null).exports,arithmeticDialog6:e("C7Lr")(null,d,!1,null,null,null).exports,arithmeticDialog7:e("C7Lr")(null,c,!1,null,null,null).exports,arithmeticDialog8:e("C7Lr")(null,_,!1,null,null,null).exports,arithmeticDialog9:e("C7Lr")(null,r,!1,null,null,null).exports},data:function(){return{showModal:!1,tabview:"arithmeticDialog1",cardDatas:[{fatherType:"1",name:"二分类算法",cardData:[{name:"逻辑回归-二分类",content:"LR（Logistic Regression）逻辑回归是业界常用的监督学习算法，常见用于对类别的预测，可以完成高维度，大样本数据下的快速建模场景",childType:"1"},{name:"随机森林-二分类",content:"随机森林 (Random Forest) 是一种基于bagging思想的决策树算法。随机森林模型由多棵决策树组成，通过将多棵决策树预测结果进行投票，相比单个决策树有效降低了模型的方差（variance）",childType:"2"},{name:"朴素贝叶斯-二分类",content:"NB是Naive Bayes的缩写，即朴素贝叶斯，它是基于贝叶斯定理与特征条件独立假设的分类方法。",childType:"3"},{name:"梯度提升决策树(GBDT)",content:"LR（Logistic Regression）逻辑回归是业界常用的监督学习算法，常见用于对类别的预测，可以完成高维度，大样本数据下的快速建模场景",childType:"4"},{name:"支持向量机(SVM)",content:"支持向量机（简称SVM）是一种经典的分类模型，分类学习最基本的思想就是基于某个训练集，在样本空间中找到一个划分超平面，将不同类别的样本分开",childType:"5"}]},{fatherType:"2",name:"多分类算法",cardData:[{name:"逻辑回归-多分类",content:"逻辑回归-多分类，是LR（Logistic regression）在多分类的推广，与LR一样，同属于广义线性模型",childType:"6"}]},{fatherType:"3",name:"回归算法",cardData:[{name:"线性回归",content:"线性回归（Linear regression）是回归分析中第一种经过严格研究并在实际应用中广泛使用的模型",childType:"7"},{name:"梯度提升回归树(GBRT)",content:"GBRT(Gradient Boosted Regression Tree)，即梯度提升回归树，是一种基于迭代的回归树算法，其核心就在于，每一棵树是从之前所有树的残差中来学习的，适用于回归预测问题",childType:"8"}]},{fatherType:"4",name:"聚类算法",cardData:[{name:"K-Means",content:"K-Means是一种聚类分析算法，聚类是指试图将数据集中的样本划分为若干个通常是不相干的子集，每个子集称为一个“簇”，通过这样的划分，每个簇可能对应于一些潜在的类别",childType:"9"}]}]}},methods:{viewDetails:function(t){this.showModal=!0,this.tabview="arithmeticDialog"+t,this.dataObj={type:t}},cancel:function(){}}},C={render:function(){var t=this,i=t.$createElement,s=t._self._c||i;return s("div",{staticClass:"machine-learn"},[t._m(0),t._v(" "),s("div",{staticClass:"content"},t._l(t.cardDatas,function(i){return s("div",{staticClass:"content-detail"},[s("div",{staticClass:"contentCellTitle"},[s("div",{staticClass:"contentCellTitle-1"}),t._v(t._s(i.name)+"\n          ")]),t._v(" "),t._l(i.cardData,function(i){return s("div",{staticClass:"details",on:{click:function(e){return t.viewDetails(i.childType)}}},[s("img",{attrs:{src:e("Rfsj"),alt:""}}),t._v(" "),s("div",{staticClass:"wrapper"},[s("div",{staticClass:"title"},[t._v(t._s(i.name))]),t._v(" "),s("div",{staticClass:"detail"},[t._v("\n                      "+t._s(i.content)+"\n                  ")])])])})],2)}),0),t._v(" "),s("Modal",{staticClass:"dialog",attrs:{"mask-closable":!1,title:"算法介绍",styles:{width:"70%"}},on:{"on-cancel":t.cancel},model:{value:t.showModal,callback:function(i){t.showModal=i},expression:"showModal"}},[s(t.tabview,{tag:"component",attrs:{width:"80%"}}),t._v(" "),s("div",{attrs:{slot:"footer"},slot:"footer"})],1)],1)},staticRenderFns:[function(){var t=this.$createElement,i=this._self._c||t;return i("div",{staticClass:"topTitle"},[i("span",{staticClass:"topTitle-span1"},[this._v("机器学习")]),this._v(" "),i("span",{staticClass:"topTitle-span1"},[i("img",{attrs:{src:e("Dh6M"),alt:""}})]),this._v(" "),i("span",{staticClass:"topTitle-span1"},[this._v("机器学习算法")])])}]};var u=e("C7Lr")(o,C,!1,function(t){e("JfYe")},"data-v-52b3e7ae",null);i.default=u.exports}});
//# sourceMappingURL=28.5d8ef5784b982b0f777e1577069638620.js.map